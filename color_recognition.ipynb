{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TP - √ânonc√© - Reconnaissance de couleurs üè≥‚Äçüåà\n",
    "\n",
    "## 0 - Objectifs\n",
    "\n",
    "L'objectif de ce TP est de r√©aliser une application Python de reconnaissance de couleurs. On cherche √† pouvoir d√©terminer la classe de couleur (au format texte) √† laquelle appartient une couleur RGB.\n",
    "\n",
    "Quelques exemples de fonctionnement de l'application :\n",
    "\n",
    "| R (in) | G (in) | B (in) | Couleur la plus proche (out) |\n",
    "|--------|--------|--------|------------------------------|\n",
    "| 240    | 5      | 2      | üü• Rouge                     |\n",
    "| 255    | 5      | 250    | üü™ Fuschia                   |\n",
    "| 0      | 120    | 0      | üü© Vert                      |\n",
    "\n",
    "L'id√©e ici est donc de concevoir un premier programme qui va g√©n√©rer un dataset de couleurs, puis un second int√©grant un r√©seau de neuronnes qui va apprendre √† reconna√Ætre les couleurs par lui-m√™me, avec un taux d'erreur minime. Enfin, vous comparerez la performance des deux programmes pour d√©terminer lequel est le plus efficace."
   ],
   "metadata": {
    "id": "5gpuHdYZgS6b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 - Pr√©requis\n",
    "\n",
    "Vous devez r√©aliser ce TP en Python, nous vous recommandons d'utiliser **[Python 3](https://www.python.org/downloads/)** pour √©viter des probl√®mes de compatibilit√© avec les librairies requises.\n",
    "\n",
    "Pensez √† installer, avant la s√©ance, les librairies **[pandas](https://gifts.worldwildlife.org/gift-center/gifts/Species-Adoptions/Panda.aspx?sc=AWY2005OQ18318A03785RX&_ga=2.160781181.1170045420.1668093542-311135590.1668093541)** et **[tensorflow_datasets](https://www.tensorflow.org/tutorials/quickstart/beginner)** (data generation), ainsi que **[sklearn](https://scikit-learn.org/stable/getting_started.html)** (data management).\n",
    "\n",
    "[https://pandas.pydata.org/](https://pandas.pydata.org/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 2 - G√©n√©ration du dataset\n",
    "\n",
    "*Votre environnement de dev est pr√™t ? Alors c'est parti, on peut commencer √† mettre les mains dans le cambouis !*\n",
    "\n",
    "Avant de pouvoir entra√Æner le mod√®le de notre application, on a besoin de donn√©es √† lui fournir.\n",
    "\n",
    "> üí° **Remarque** : il ne vous aura pas √©chapp√© que le probl√®me abord√© dans ce TP est tr√®s simpliste... Dans les faits, cette simplicit√© permet de :\n",
    ">  - g√©n√©rer des datasets complets (variables explicatives / √† expliquer) √† l'aide d'un algorithme \"classique\"\n",
    ">  - pouvoir adapter la taille du dataset pour observer les changements de comportements de notre mod√®le\n",
    "\n",
    "Le code ci-dessous permet de g√©n√©rer un dataset √† la taille voulue, **ne pas le modifier** :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# constantes\n",
    "\n",
    "COLORS = {\n",
    "    \"black\": (0, 0, 0),\n",
    "    \"silver\": (192, 192, 192),\n",
    "    \"gray\": (128, 128, 128),\n",
    "    \"white\": (255, 255, 255),\n",
    "    \"maroon\": (128, 0, 0),\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"fuchsia\": (255, 0, 255),\n",
    "    \"green\": (0, 128, 0),\n",
    "    \"lime\": (0, 255, 0),\n",
    "    \"olive\": (128, 128, 0),\n",
    "    \"yellow\": (255, 255, 0),\n",
    "    \"navy\": (0, 0, 128),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"teal\": (0, 128, 128),\n",
    "    \"aqua\": (0, 255, 255)\n",
    "}\n",
    "\n",
    "Y_LABEL = \"Value\"\n",
    "\n",
    "\n",
    "def random_rgb():\n",
    "    \"\"\"\n",
    "    G√©n√®re un tuple RGB.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255)\n",
    "    )\n",
    "\n",
    "\n",
    "def to_decimal(rgb):\n",
    "    \"\"\"\n",
    "    Convertie un tuple rgb qui a pour valeur 0 √† 255 vers des valeurs entre -0.5 et 0.5.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    return (\n",
    "        r / 255 - 0.5,\n",
    "        g / 255 - 0.5,\n",
    "        b / 255 - 0.5\n",
    "    )\n",
    "\n",
    "def to_hex(rgb):\n",
    "    \"\"\"\n",
    "    Convertie un tuple rgb qui a pour valeur -0.5 √† 0.5 vers des valeurs entre 0 et 255.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    return (\n",
    "        int((r + 0.5) * 255),\n",
    "        int((g + 0.5) * 255),\n",
    "        int((b + 0.5) * 255)\n",
    "    )\n",
    "\n",
    "\n",
    "def closest_color(rgb):\n",
    "    \"\"\"\n",
    "    D√©termine √† partir d'une couleur en RGB son nom associ√©.\n",
    "    (ici on r√©alise exactement l'op√©ration que le r√©seau de neurone sera amen√© √† effectuer plus\n",
    "    tard).\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    color_diffs = []\n",
    "    for color_name in COLORS:\n",
    "        cr, cg, cb = COLORS[color_name]\n",
    "        color_diff = math.sqrt((r - cr) ** 2 + (g - cg) ** 2 + (b - cb) ** 2)\n",
    "        color_diffs.append((color_diff, COLORS[color_name], color_name))\n",
    "    return min(color_diffs)[2]\n",
    "\n",
    "\n",
    "def create_dataset(n):\n",
    "    \"\"\"\n",
    "    G√©n√®re un dataset qui contient 4 colonnes: R, G, B, ColorName\n",
    "    \"\"\"\n",
    "    dataset_array = []\n",
    "    for _ in range(n):\n",
    "        rgb_color = random_rgb()\n",
    "        r, g, b = rgb_color\n",
    "        rc, gc, bc = to_decimal(rgb_color)\n",
    "        dataset_array.append([rc, gc, bc, closest_color((r, g, b))])\n",
    "    return pd.DataFrame(data=dataset_array, columns=[\"R\", \"G\", \"B\", Y_LABEL])"
   ],
   "metadata": {
    "id": "nLSgdkIKwWLj"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modifiez l'appel √† la cellule suivante pour g√©rer la taille de vos donn√©es."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "          R         G         B   Value\n0  0.249020  0.052941  0.241176  silver\n1  0.374510  0.170588 -0.147059  silver\n2  0.319608 -0.158824 -0.358824   olive\n3  0.033333 -0.013725 -0.425490   olive\n4  0.056863  0.029412 -0.017647    gray",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R</th>\n      <th>G</th>\n      <th>B</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.249020</td>\n      <td>0.052941</td>\n      <td>0.241176</td>\n      <td>silver</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.374510</td>\n      <td>0.170588</td>\n      <td>-0.147059</td>\n      <td>silver</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.319608</td>\n      <td>-0.158824</td>\n      <td>-0.358824</td>\n      <td>olive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.033333</td>\n      <td>-0.013725</td>\n      <td>-0.425490</td>\n      <td>olive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.056863</td>\n      <td>0.029412</td>\n      <td>-0.017647</td>\n      <td>gray</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = create_dataset(100_000)\n",
    "ds.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 - Pr√©paration des donn√©es\n",
    "\n",
    "Maintenant que vos donn√©es sont pr√™tes, vous allez les pr√©parer pour faciliter leur traitement.\n",
    "\n",
    " - a) Ramenez les valeurs du dataset entre 0 et 1.\n",
    " - b) S√©parez les variables explicatives \"X\" et √† expliquer \"Y\".\n",
    " - c) S√©parez le dataset en lots d'entrainement (train) et de test (test) pour vous retrouver avec les variables :\n",
    "   - **X_train**\n",
    "   - **y_train**\n",
    "   - **X_test**\n",
    "   - **y_test**\n",
    "\n",
    "> üí° Remarque : pensez √† utiliser la librairie **[sklearn](https://scikit-learn.org/stable/getting_started.html)** pour la s√©paration des donn√©es"
   ],
   "metadata": {
    "id": "mYk_7Re31b73"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# obtention des x\n",
    "X = ds.loc[:, ds.columns != Y_LABEL]\n",
    "\n",
    "# obtention d'y\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(ds[Y_LABEL])  # transforme les classes en valeurs num√©riques (\"aqua\" --> 0)\n",
    "y = pd.DataFrame(y, columns=[Y_LABEL])  # reconversion d'y en DataFrame Pandas\n",
    "\n",
    "# S√©paration des donn√©es d'entrainement et des donn√©es de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 - Cr√©ation du mod√®le\n",
    "\n",
    "### **TensorFlow** (pour les curieux üîé)\n",
    "TensorFlow est une biblioth√®que open source de Machine Learning, cr√©√©e par Google, permettant de d√©velopper et d‚Äôex√©cuter des applications de Machine Learning et de Deep Learning.\n",
    "\n",
    "### **Keras** (pour les curieux üîé)\n",
    "\n",
    "Keras est une API de r√©seau de neurones √©crite en langage Python. Il s‚Äôagit d‚Äôune biblioth√®que Open Source, qui est ex√©cut√©e au-dessus du framework TensorFlow.\n",
    "\n",
    "Aujourd‚Äôhui, Keras est l‚Äôune des APIs de r√©seaux de neurones les plus utilis√©es pour le d√©veloppement et le testing de r√©seaux de neurones. Elle permet de cr√©er tr√®s facilement des \"layers\" pour les r√©seaux de neurones ou de mettre en place des architectures complexes.\n",
    "\n",
    "### **Du code, du code, on veut coder !!** ü§™\n",
    "\n",
    "... d√©brouille toi."
   ],
   "metadata": {
    "id": "m6jqE3VirZvw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E3jvOIyErUJy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 23:39:57.533748: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-13 23:39:57.642706: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-13 23:39:57.646192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-13 23:39:57.646204: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-13 23:39:57.665113: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-13 23:39:58.081090: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-13 23:39:58.081131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-13 23:39:58.081134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-13 23:39:58.473994: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-13 23:39:58.474011: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-13 23:39:58.474023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (KAEDUS): /proc/driver/nvidia/version does not exist\n",
      "2022-11-13 23:39:58.474170: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SIZE = 3\n",
    "OUTPUT_SIZE = len(COLORS)\n",
    "HIDDEN_LAYER_NUMBER = 2\n",
    "HIDDEN_LAYER_NODE_NUMBER = abs(OUTPUT_SIZE - INPUT_SIZE) // 2\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# TODO find adequate model\n",
    "\n",
    "# input layer\n",
    "model.add(tf.keras.layers.Input(shape=(INPUT_SIZE,)))\n",
    "# hidden layers\n",
    "for _ in range(HIDDEN_LAYER_NUMBER):\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        HIDDEN_LAYER_NODE_NUMBER,\n",
    "        activation=\"relu\",\n",
    "    ))\n",
    "# output layer\n",
    "model.add(tf.keras.layers.Dense(OUTPUT_SIZE, activation=\"softmax\"))\n",
    "\n",
    "# model compilation\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entra√Ænement"
   ],
   "metadata": {
    "id": "UqJaMEoJ4A5H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=10)"
   ],
   "metadata": {
    "id": "NT0uKDMz4mHt"
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 6s 694us/step - loss: 0.7096 - accuracy: 0.7983\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 5s 684us/step - loss: 0.2190 - accuracy: 0.9415\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 5s 677us/step - loss: 0.1597 - accuracy: 0.9592\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 5s 670us/step - loss: 0.1302 - accuracy: 0.9669\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 5s 660us/step - loss: 0.1130 - accuracy: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fbafa9a2c20>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## √âvaluation"
   ],
   "metadata": {
    "id": "8qsg2OMs4FFT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"accuracy: {accuracy:.2f}\\nloss: {loss:.2f}\")"
   ],
   "metadata": {
    "id": "TSibR8OU4tDE"
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 602us/step - loss: 0.1136 - accuracy: 0.9628\n",
      "accuracy: 0.96\n",
      "loss: 0.11\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pr√©dictions"
   ],
   "metadata": {
    "id": "0x0wx5pv0ylf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from numpy import argmax\n",
    "\n",
    "\n",
    "# entr√©e\n",
    "row = ds.sample()\n",
    "rgb_ = to_hex((row.R, row.G, row.B))\n",
    "print(f\"[input]:\\n{rgb_} --- should be --> {row.Value.values[0]}\\n\")\n",
    "random_input = row.iloc[:, ds.columns != Y_LABEL]\n",
    "\n",
    "# pr√©diction\n",
    "output_vec = model.predict(random_input, verbose=\"silent\")\n",
    "\n",
    "# sortie\n",
    "color_index = argmax(output_vec)\n",
    "color = le.classes_[color_index]\n",
    "print(f\"[output]\\n{color}\\n\")"
   ],
   "metadata": {
    "id": "x24-GWNR019E"
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[input]:\n",
      "(37, 86, 167) --- should be --> teal\n",
      "\n",
      "[output]\n",
      "teal\n",
      "\n"
     ]
    }
   ]
  }
 ]
}
