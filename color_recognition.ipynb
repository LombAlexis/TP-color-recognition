{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reconnaissance de couleur par réseau de neurones"
   ],
   "metadata": {
    "id": "5gpuHdYZgS6b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "TODO regrouper dans le notebook le code de génération et l'énoncé.\n",
    "\n",
    "TODO création du dataset à la place de faire un csv externe pour le réimporter derrière\n",
    "- avec tensorflow_dataset ?\n",
    "- avec pandas ?\n",
    "- avec un tableau tout bête (numpy ?) ?\n",
    "\n",
    "opinion superficielle : avec pandas c'est facile\n",
    "\n",
    "génération de données avec pandas :\n",
    "https://towardsdatascience.com/generating-fake-data-with-pandas-very-quickly-b99467d4c618\n",
    "\n",
    "utilisation de dataset pandas avec tensorflow :\n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "génération de données avec tensorlfow_dataset :\n",
    "https://www.tensorflow.org/datasets/add_dataset#dataset_example\n",
    "\n",
    "\n",
    "Liens utiles\n",
    "\n",
    "vue d'ensemble tensorflow :\n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner#build_a_machine_learning_model\n",
    "\n",
    "exemple d'utilisation complète et simple (utilise un tableau pour les données):\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "méthode de séparation des données sur un dataset existant :\n",
    "https://stackoverflow.com/a/50185329/17987233\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "20ILroQNimwo",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "outputId": "eb9cf274-b48f-45ed-946e-eef07624973c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nTODO création du dataset à la place de faire un csv externe pour le réimporter derrière\\n- avec tensorflow_dataset ?\\n- avec pandas ?\\n- avec un tableau tout bête (numpy ?) ?\\n\\ngénération de données avec pandas :\\nhttps://towardsdatascience.com/generating-fake-data-with-pandas-very-quickly-b99467d4c618\\n\\nutilisation de dataset pandas avec tensorflow :\\nhttps://www.tensorflow.org/tutorials/load_data/pandas_dataframe\\n\\n\\nvue d'ensemble tensorflow :\\nhttps://www.tensorflow.org/tutorials/quickstart/beginner#build_a_machine_learning_model\\n\\nexemple d'utilisation complète et simple (utilise un tableau pour les données):\\nhttps://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\\n\\nméthode de séparation des données sur un dataset existant :\\nhttps://stackoverflow.com/a/50185329/17987233\\n\\ngénération de données avec tensorlfow_dataset :\\nhttps://www.tensorflow.org/datasets/add_dataset#dataset_example\\n\""
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Génération du dataset\n",
    "\n",
    "Exécutez cette cellule sans la modifier pour générez votre dataset, qui sera stocké dans la variable `ds`."
   ],
   "metadata": {
    "id": "3lkpXwmm1Xq8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "COLORS = {\n",
    "    \"black\"     : (0,0,0),\n",
    "    \"silver\"    : (192,192,192),\n",
    "    \"gray\"      : (128,128,128),\n",
    "    \"white\"     : (255,255,255),\n",
    "    \"maroon\"    : (128,0,0),\n",
    "    \"red\"       : (255,0,0),\n",
    "    \"purple\"    : (128,0,128),\n",
    "    \"fuchsia\"   : (255,0,255),\n",
    "    \"green\"     : (0,128,0),\n",
    "    \"lime\"      : (0,255,0),\n",
    "    \"olive\"     : (128,128,0),\n",
    "    \"yellow\"    : (255,255,0),\n",
    "    \"navy\"      : (0,0,128),\n",
    "    \"blue\"      : (0,0,255),\n",
    "    \"teal\"      : (0,128,128),\n",
    "    \"aqua\"      : (0,255,255)\n",
    "}\n",
    "\n",
    "\n",
    "def random_rgb():\n",
    "    \"\"\"\n",
    "    Génère un tuple RGB.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        random.randint(0, 255), \n",
    "        random.randint(0, 255), \n",
    "        random.randint(0, 255)\n",
    "        )\n",
    "\n",
    "\n",
    "def convert(rgb):\n",
    "    \"\"\"\n",
    "    Convertie un tuple rgb qui a pour valeur 0 à 255 vers des valeurs entre 0 et 1.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    return r / 255, g / 255, b / 255\n",
    "\n",
    "\n",
    "def closest_color(rgb):\n",
    "    \"\"\"\n",
    "    On détermine à partir d'un couleur en RGB son nom associé\n",
    "    (ici on réalise exactement l'opération que le réseau de neurone sera amené à effectuer plus \n",
    "    tard).\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    color_diffs = []\n",
    "    for color_name in COLORS:\n",
    "        cr, cg, cb = COLORS[color_name]\n",
    "        color_diff = math.sqrt((r - cr)**2 + (g - cg)**2 + (b - cb)**2)\n",
    "        color_diffs.append((color_diff, COLORS[color_name], color_name))\n",
    "    return min(color_diffs)[2]\n",
    "\n",
    "\n",
    "# Génère un fichier nommé Dataset.csv\n",
    "# Il contient 4 colonnes: R, G, B, ColorName\n",
    "\n",
    "# with open('Dataset.csv', 'w', newline='') as file_:\n",
    "#     csv_file = csv.writer(file_, delimiter=',')\n",
    "\n",
    "#     print(\"Create a dataset of: \" + sys.argv[1] + \" called Dataset.csv\")\n",
    "#     for _ in range(int(sys.argv[1])):\n",
    "#         rgb_color = random_rgb()\n",
    "#         r, g, b = rgb_color\n",
    "#         rgb_converted = convert(rgb_color)\n",
    "#         rc, gc, bc = rgb_converted\n",
    "#         csv_file.writerow([rc, gc, bc, closest_color((r, g, b))])\n"
   ],
   "metadata": {
    "id": "nLSgdkIKwWLj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Préparation des données\n",
    "\n",
    "Ramenez les valeurs du dataset entre 0 et 1.  \n",
    "Séparez vos variables explicatives et à expliquer `X` et `y`.  \n",
    "Séparez le dataset en lots d'entrainement et de test, pour vous retrouver avec les variables `X_train`, `y_train`, `X_test`, `y_test`."
   ],
   "metadata": {
    "id": "mYk_7Re31b73"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO dataset preprocess"
   ],
   "metadata": {
    "id": "-JBrED781jrF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création du modèle\n",
    "\n",
    "Créez un modèle possédant le nombre d'entrées et le nombre de sorties adéquat.\n",
    "\n",
    "Vous devrez choisir :\n",
    "- le nombre de couches internes et de neurones\n",
    "- la fonction d'activation\n",
    "- la fonction de perte\n",
    "\n",
    "On utilisera la fonction d'optimisation \"adam\".\n",
    "\n",
    "Servez-vous des fonctions `Sequential()`, `Input()`, `Dense()` pour créer le modèle.  \n",
    "Une fois le modèle créé, il se compile avec la fonction `compile()`."
   ],
   "metadata": {
    "id": "m6jqE3VirZvw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3jvOIyErUJy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SIZE = 3\n",
    "OUTPUT_SIZE = len(COLORS)\n",
    "HIDDEN_LAYER_NUMBER = 3\n",
    "HIDDEN_LAYER_NODE_NUMBER = 16\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(tf.keras.layers.Input(shape=(INPUT_SIZE,)))\n",
    "\n",
    "# hidden layers\n",
    "for _ in range(HIDDEN_LAYER_NUMBER):\n",
    "    model.add(tf.keras.layers.Dense(HIDDEN_LAYER_NODE_NUMBER, activation='softmax'))\n",
    "\n",
    "# output layer\n",
    "model.add(tf.keras.layers.Dense(OUTPUT_SIZE))\n",
    "\n",
    "# model compilation\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entraînement\n",
    "\n",
    "Servez-vous de la fonction `fit()` pour entraîner le modèle avec vos données.\n",
    "\n",
    "Vous devrez choisir :\n",
    "- le nombre d'epochs\n",
    "- la taille des lots"
   ],
   "metadata": {
    "id": "UqJaMEoJ4A5H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(X_train, y_train, epochs=10_000, batch_size=10)"
   ],
   "metadata": {
    "id": "NT0uKDMz4mHt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Évaluation"
   ],
   "metadata": {
    "id": "8qsg2OMs4FFT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"accuracy: {accuracy}\\nloss: {loss}\")"
   ],
   "metadata": {
    "id": "TSibR8OU4tDE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prédictions"
   ],
   "metadata": {
    "id": "0x0wx5pv0ylf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO predictions"
   ],
   "metadata": {
    "id": "x24-GWNR019E"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
