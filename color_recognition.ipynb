{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TP - √ânonc√© - Reconnaissance de couleurs üè≥‚Äçüåà\n",
    "\n",
    "## 0 - Objectifs\n",
    "\n",
    "L'objectif de ce TP est de r√©aliser une application Python de reconnaissance de couleurs. On cherche √† pouvoir d√©terminer la classe de couleur (au format texte) √† laquelle appartient une couleur RGB.\n",
    "\n",
    "Quelques exemples de fonctionnement de l'application :\n",
    "\n",
    "| R (in) | G (in) | B (in) | Couleur la plus proche (out) |\n",
    "|--------|--------|--------|------------------------------|\n",
    "| 240    | 5      | 2      | üü• Rouge                     |\n",
    "| 255    | 5      | 250    | üü™ Fuschia                   |\n",
    "| 0      | 120    | 0      | üü© Vert                      |\n",
    "\n",
    "L'id√©e ici est donc de concevoir un premier programme qui va g√©n√©rer un dataset de couleurs, puis un second int√©grant un r√©seau de neuronnes qui va apprendre √† reconna√Ætre les couleurs par lui-m√™me, avec un taux d'erreur minime. Enfin, vous comparerez la performance des deux programmes pour d√©terminer lequel est le plus efficace."
   ],
   "metadata": {
    "id": "5gpuHdYZgS6b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 - Pr√©requis\n",
    "\n",
    "Vous devez r√©aliser ce TP en Python, nous vous recommandons d'utiliser **[Python 3](https://www.python.org/downloads/)** pour √©viter des probl√®mes de compatibilit√© avec les librairies requises.\n",
    "\n",
    "Pensez √† installer, avant la s√©ance, les librairies **[pandas](https://gifts.worldwildlife.org/gift-center/gifts/Species-Adoptions/Panda.aspx?sc=AWY2005OQ18318A03785RX&_ga=2.160781181.1170045420.1668093542-311135590.1668093541)** et **[tensorflow_datasets](https://www.tensorflow.org/tutorials/quickstart/beginner)** (data generation), ainsi que **[sklearn](https://scikit-learn.org/stable/getting_started.html)** (data management).\n",
    "\n",
    "[https://pandas.pydata.org/](https://pandas.pydata.org/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 2 - G√©n√©ration du dataset\n",
    "\n",
    "*Votre environnement de dev est pr√™t ? Alors c'est parti, on peut commencer √† mettre les mains dans le cambouis !*\n",
    "\n",
    "Avant de pouvoir entra√Æner le mod√®le de notre application, on a besoin de donn√©es √† lui fournir.\n",
    "\n",
    "> üí° **Remarque** : il ne vous aura pas √©chapp√© que le probl√®me abord√© dans ce TP est tr√®s simpliste... Dans les faits, cette simplicit√© permet de :\n",
    ">  - g√©n√©rer des datasets complets (variables explicatives / √† expliquer) √† l'aide d'un algorithme \"classique\"\n",
    ">  - pouvoir adapter la taille du dataset pour observer les changements de comportements de notre mod√®le\n",
    "\n",
    "Le code ci-dessous permet de g√©n√©rer un dataset √† la taille voulue, **ne pas le modifier** :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# constantes\n",
    "\n",
    "COLORS = {\n",
    "    \"black\": (0, 0, 0),\n",
    "    \"silver\": (192, 192, 192),\n",
    "    \"gray\": (128, 128, 128),\n",
    "    \"white\": (255, 255, 255),\n",
    "    \"maroon\": (128, 0, 0),\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"fuchsia\": (255, 0, 255),\n",
    "    \"green\": (0, 128, 0),\n",
    "    \"lime\": (0, 255, 0),\n",
    "    \"olive\": (128, 128, 0),\n",
    "    \"yellow\": (255, 255, 0),\n",
    "    \"navy\": (0, 0, 128),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"teal\": (0, 128, 128),\n",
    "    \"aqua\": (0, 255, 255)\n",
    "}\n",
    "\n",
    "Y_LABEL = \"Value\"\n",
    "\n",
    "\n",
    "def random_rgb():\n",
    "    \"\"\"\n",
    "    G√©n√®re un tuple RGB.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255)\n",
    "    )\n",
    "\n",
    "\n",
    "def to_decimal(rgb):\n",
    "    \"\"\"\n",
    "    Convertie un tuple rgb qui a pour valeur 0 √† 255 vers des valeurs entre -0.5 et 0.5.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    return (\n",
    "        r / 255 - 0.5,\n",
    "        g / 255 - 0.5,\n",
    "        b / 255 - 0.5\n",
    "    )\n",
    "\n",
    "def to_hex(rgb):\n",
    "    \"\"\"\n",
    "    Convertie un tuple rgb qui a pour valeur -0.5 √† 0.5 vers des valeurs entre 0 et 255.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    return (\n",
    "        int((r + 0.5) * 255),\n",
    "        int((g + 0.5) * 255),\n",
    "        int((b + 0.5) * 255)\n",
    "    )\n",
    "\n",
    "\n",
    "def closest_color(rgb):\n",
    "    \"\"\"\n",
    "    D√©termine √† partir d'une couleur en RGB son nom associ√©.\n",
    "    (ici on r√©alise exactement l'op√©ration que le r√©seau de neurone sera amen√© √† effectuer plus\n",
    "    tard).\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    color_diffs = []\n",
    "    for color_name in COLORS:\n",
    "        cr, cg, cb = COLORS[color_name]\n",
    "        color_diff = math.sqrt((r - cr) ** 2 + (g - cg) ** 2 + (b - cb) ** 2)\n",
    "        color_diffs.append((color_diff, COLORS[color_name], color_name))\n",
    "    return min(color_diffs)[2]\n",
    "\n",
    "\n",
    "def create_dataset(n):\n",
    "    \"\"\"\n",
    "    G√©n√®re un dataset qui contient 4 colonnes: R, G, B, ColorName\n",
    "    \"\"\"\n",
    "    dataset_array = []\n",
    "    for _ in range(n):\n",
    "        rgb_color = random_rgb()\n",
    "        r, g, b = rgb_color\n",
    "        rc, gc, bc = to_decimal(rgb_color)\n",
    "        dataset_array.append([rc, gc, bc, closest_color((r, g, b))])\n",
    "    return pd.DataFrame(data=dataset_array, columns=[\"R\", \"G\", \"B\", Y_LABEL])"
   ],
   "metadata": {
    "id": "nLSgdkIKwWLj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modifiez l'appel √† la cellule suivante pour g√©rer la taille de vos donn√©es."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds = create_dataset(100_000)\n",
    "ds.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 - Pr√©paration des donn√©es\n",
    "\n",
    "Maintenant que vos donn√©es sont pr√™tes, vous allez les pr√©parer pour faciliter leur traitement.\n",
    "\n",
    " - a) Ramenez les valeurs du dataset entre 0 et 1.\n",
    " - b) S√©parez les variables explicatives \"X\" et √† expliquer \"Y\".\n",
    " - c) S√©parez le dataset en lots d'entrainement (train) et de test (test) pour vous retrouver avec les variables :\n",
    "   - **X_train**\n",
    "   - **y_train**\n",
    "   - **X_test**\n",
    "   - **y_test**\n",
    "\n",
    "> üí° Remarque : pensez √† utiliser la librairie **[sklearn](https://scikit-learn.org/stable/getting_started.html)** pour la s√©paration des donn√©es"
   ],
   "metadata": {
    "id": "mYk_7Re31b73"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# obtention des x\n",
    "X = ds.loc[:, ds.columns != Y_LABEL]\n",
    "\n",
    "# obtention d'y\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(ds[Y_LABEL])  # transforme les classes en valeurs num√©riques (\"aqua\" --> 0)\n",
    "y = pd.DataFrame(y, columns=[Y_LABEL])  # reconversion d'y en DataFrame Pandas\n",
    "\n",
    "# S√©paration des donn√©es d'entrainement et des donn√©es de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 - Cr√©ation du mod√®le\n",
    "\n",
    "### **TensorFlow** (pour les curieux üîé)\n",
    "TensorFlow est une biblioth√®que open source de Machine Learning, cr√©√©e par Google, permettant de d√©velopper et d‚Äôex√©cuter des applications de Machine Learning et de Deep Learning.\n",
    "\n",
    "### **Keras** (pour les curieux üîé)\n",
    "\n",
    "Keras est une API de r√©seau de neurones √©crite en langage Python. Il s‚Äôagit d‚Äôune biblioth√®que Open Source, qui est ex√©cut√©e au-dessus du framework TensorFlow.\n",
    "\n",
    "Aujourd‚Äôhui, Keras est l‚Äôune des APIs de r√©seaux de neurones les plus utilis√©es pour le d√©veloppement et le testing de r√©seaux de neurones. Elle permet de cr√©er tr√®s facilement des \"layers\" pour les r√©seaux de neurones ou de mettre en place des architectures complexes.\n",
    "\n",
    "### **Du code, du code, on veut coder !!** ü§™\n",
    "\n",
    "... d√©brouille toi."
   ],
   "metadata": {
    "id": "m6jqE3VirZvw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3jvOIyErUJy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SIZE = 3\n",
    "OUTPUT_SIZE = len(COLORS)\n",
    "HIDDEN_LAYER_NUMBER = 2\n",
    "HIDDEN_LAYER_NODE_NUMBER = abs(OUTPUT_SIZE - INPUT_SIZE) // 2\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# TODO find adequate model\n",
    "\n",
    "# input layer\n",
    "model.add(tf.keras.layers.Input(shape=(INPUT_SIZE,)))\n",
    "# hidden layers\n",
    "for _ in range(HIDDEN_LAYER_NUMBER):\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        HIDDEN_LAYER_NODE_NUMBER,\n",
    "        activation=\"relu\",\n",
    "    ))\n",
    "# output layer\n",
    "model.add(tf.keras.layers.Dense(OUTPUT_SIZE, activation=\"softmax\"))\n",
    "\n",
    "# model compilation\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entra√Ænement"
   ],
   "metadata": {
    "id": "UqJaMEoJ4A5H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=10)"
   ],
   "metadata": {
    "id": "NT0uKDMz4mHt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## √âvaluation"
   ],
   "metadata": {
    "id": "8qsg2OMs4FFT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"accuracy: {accuracy:.2f}\\nloss: {loss:.2f}\")"
   ],
   "metadata": {
    "id": "TSibR8OU4tDE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pr√©dictions"
   ],
   "metadata": {
    "id": "0x0wx5pv0ylf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from numpy import argmax\n",
    "\n",
    "\n",
    "# entr√©e\n",
    "row = ds.sample()\n",
    "rgb_ = to_hex((row.R, row.G, row.B))\n",
    "print(f\"[input]:\\n{rgb_} --- should be --> {row.Value.values[0]}\\n\")\n",
    "random_input = row.iloc[:, ds.columns != Y_LABEL]\n",
    "\n",
    "# pr√©diction\n",
    "output_vec = model.predict(random_input, verbose=\"silent\")\n",
    "\n",
    "# sortie\n",
    "color_index = argmax(output_vec)\n",
    "color = le.classes_[color_index]\n",
    "print(f\"[output]\\n{color}\\n\")"
   ],
   "metadata": {
    "id": "x24-GWNR019E"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
